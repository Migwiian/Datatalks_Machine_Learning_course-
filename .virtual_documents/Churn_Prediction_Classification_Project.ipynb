


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split


data = "'https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-03-churn-prediction/WA_Fn-UseC_-Telco-Customer-Churn.csv'"


!wget $data -O data-week-3.csv 


df = pd.read_csv("data-week-3.csv")
df.head()


df.columns = df.columns.str.lower().str.replace(" ", "_")





# Here we list all the columns types
print(df.dtypes)


#
print(df.dtypes[df.dtypes == 'object'])


'''What it does: Creates a boolean mask where:
True = column has dtype 'object' (typically strings/categorical data)
False = column has other dtypes (i
nt64, float64, etc.)
Prints where the condition is true'''
print(df.dtypes[df.dtypes == 'object'].index)


#Converts the Index object to a regular Python list.
print(list(df.dtypes[df.dtypes == 'object'].index))


df.columns = df.columns.str.lower().str.replace(' ', '_')

categorical_columns = list(df.dtypes[df.dtypes == 'object'].index)

for c in categorical_columns:
    df[c] = df[c].str.lower().str.replace(' ', '_')


df.head().T


# Use this as a safety check for the conversion
tc = pd.to_numeric(df.totalcharges, errors='coerce')


# The actual change to the column
df.totalcharges = pd.to_numeric(df.totalcharges, errors='coerce')


# Replace all NaN values with 0
df.totalcharges = df.totalcharges.fillna(0)


df.churn.head()


df.churn = (df.churn == 'yes').astype(int)


df_full_train, df_test = train_test_split(df, test_size = 0.2, random_state = 1)


df_train, df_val = train_test_split(df_full_train, test_size = 0.25, random_state = 1)


len(df_full_train), len(df_val), len(df_test)





df_train = df_train.reset_index(drop=True)
df_val = df_val.reset_index(drop=True)
adf_test = df_test.reset_index(drop=True)





y_train = df_train.churn.values
y_val = df_val.churn.values
y_test = df_test.churn.values


del df_train['churn']
del df_val['churn']
del df_test['churn']





# Resetting the original indices; more orderly 
df_full_train = df_full_train.reset_index(drop = True)


# Check null values and calculate the sum per column
df_full_train.isnull().sum()


# Check the distribution of the variable 'churn'
df_full_train.churn.value_counts(normalize = True)


global_churn_rate = df_full_train.churn.mean()
round(global_churn_rate, 2)


df_full_train.dtypes


numeric = ['tenure', 'monthlycharges', 'totalcharges']


categorical = [
    'gender',
    'seniorcitizen',
    'partner',
    'dependents',
    'phoneservice',
    'multiplelines',
    'internetservice',
    'onlinesecurity',
    'onlinebackup',
    'deviceprotection',
    'techsupport',
    'streamingtv',
    'streamingmovies',
    'contract',
    'paperlessbilling',
    'paymentmethod',
]


df_full_train[categorical].nunique()





global_churn = df_full_train.churn.mean()
churn_female = df_full_train[df_full_train.gender == 'female'].churn.mean()
churn_male = df_full_train[df_full_train.gender == 'male'].churn.mean()
print(f"Global churn", global_churn)
print(f"Female churn", churn_female)
print(f"Male churn", churn_male)


df_full_train['partner'].value_counts()





global_churn = df_full_train.churn.mean()
churn_partner = df_full_train[df_full_train.partner == 'yes'].churn.mean()
churn_no_partner = df_full_train[df_full_train.partner == 'no'].churn.mean()
print(f"Global churn", global_churn)
print(f"Female churn", churn_female)
print(f"Male churn", churn_male)








churn_no_partner / global_churn


churn_partner / global_churn








df_full_train.groupby('gender').churn.mean()


df_full_train.groupby('gender').churn.agg(['mean'], ['count'])


df_group = df_full_train.groupby('gender').churn.agg(['mean'], ['count'])
df_group['diff'] = df_group['mean'] - global_churn
df_group['risk'] = df_group['mean'] / global_churn
df_group


for c in categorical:
    print(c)
    df_group = df_full_train.groupby(c).churn.agg(['mean', 'count'])
    df_group['diff'] = df_group['mean'] - global_churn
    df_group['risk'] = df_group['mean'] / global_churn
    display(df_group)
    print()
    print()








from sklearn.metrics import mutual_info_score


mutual_info_score(df_full_train.churn, df_full_train.contract)


mutual_info_score(df_full_train.gender, df_full_train.churn)


mutual_info_score(df_full_train.contract, df_full_train.churn)
0.0983203874041556


mutual_info_score(df_full_train.partner, df_full_train.churn)
0.009967689095399745





def mutual_info_churn_score(series):
    """
    Calculate Mutual Information between a feature series and the churn target.
    
    This function computes how much information a single feature provides
    about the churn target variable, measuring dependency between them.
    
    Parameters
    ----------
    series : pandas.Series
        A single feature column from the DataFrame to evaluate
        
    Returns
    -------
    float
        Mutual Information score between the feature and churn.
        Higher values indicate stronger predictive power.
    """
    return mutual_info_score(series, df_full_train.churn)


mi = df_full_train[categorical].apply(mutual_info_churn_score)
mi.sort_values(ascending=False)











df_full_train[numeric].corrwith(df_full_train.churn)





df_full_train[numeric].corrwith(df_full_train.churn.abs())





df_full_train.tenure.max()  # 72





df_full_train[df_full_train.tenure <= 2].churn.mean()



df_full_train[(df_full_train.tenure > 2) & (df_full_train.tenure <= 12)].churn.mean()



df_full_train[df_full_train.tenure > 12].churn.mean()





from sklearn.feature_extraction import DictVectorizer


#first 10 values in the gender and contract column
df_train[['gender', 'contract']].iloc[:10]


#Convert into a dictionary. We use orient to target the rows. Otherwise it turns the columns
df_train[['gender', 'contract']].iloc[:10].to_dict(orient = 'records')


dicts = df_train[['gender', 'contract']].iloc[:10].to_dict(orient = 'records')


dv = DictVectorizer(sparse = False)


dv.fit(dicts)


dv.transform(dicts)


dv.get_feature_names_out()





dicts = df_train[['gender', 'contract', 'tenure']].iloc[:10].to_dict(orient = 'records')


dv = DictVectorizer(sparse = False)
dv.fit(dicts)
dv.transform(dicts)





train_dicts = df_train[categorical + numeric].to_dict(orient = 'records')
train_dicts[0]


dv.fit(train_dicts)


dv.transform(train_dicts)


#Shorter more pythonic code 
X_train  = dv.fit_transform(train_dicts)


val_dicts = df_val [categorical + numeric].to_dict(orient = 'records')


X_val = dv.transform(val_dicts)








def sigmoid(z):
    return 1 / (1 + np.exp(-z))





def linear_regression(xi):
    result = w0
    
    for j in range(len(w)):
        result = result + xi[j] * w[j]
        
    return result


def logistic_regression(xi):
    score = w0
    
    for j in range(len(w)):
        score = score + xi[j] * w[j]
        
    result = sigmoid(score)
    return result





from sklearn.linear_model import LogisticRegression





model = LogisticRegression(max_iter = 1000)
# solver='lbfgs' is the default solver in newer version of sklearn
# for older versions, you need to specify it explicitly
# Model learns the weights by minimising log-loss on training data only.
model.fit(X_train, y_train)


'''We are telling the program/python that for any prediction it makes, 
the calculation must always start with this base value. 
All the other features just get added (or subtracted) onto this number.'''
model.intercept_[0]


# The learned weight for each feature, showing its push (positive/negative) on the prediction.
model.coef_[0].round(3)


# Get the probability (confidence score) for the positive class (class 1) on the validation data.
y_pred = model.predict_proba(X_val)[:, 1]


churn_decision = (y_pred >= 0.5)


# Calculate the model's overall Accuracy on the unseen validation data.
(y_val == churn_decision).mean()





# Create an empty table (DataFrame) to compile all our results for review.
df_pred = pd.DataFrame()

# Column 1: Store the model's confidence score for each customer.
df_pred['probability'] = y_pred

# Column 2: Store the final 'Yes' (1) or 'No' (0) decision based on the 0.5 threshold.
df_pred['prediction'] = churn_decision.astype(int)

# Column 3: Store the actual true result for comparison.
df_pred['actual'] = y_val


# Create a new column checking if the prediction matches the actual result (True/False).
df_pred['correct'] = df_pred.prediction == df_pred.actual


# Calculate the mean of the 'correct' column to get the overall Accuracy score.
df_pred.correct.mean()





#List a-keys, list b-values
a = [1, 2, 3, 4]
b = 'abcd'


# Building a dictionary in a single line
dict(zip(a, b))


dict(zip(dv.get_feature_names_out(), model.coef_[0].round(3)))





# Select only the features that showed the highest impact on the churn decision.
small = ['contract', 'tenure', 'monthlycharges']


# A new list of dictionaries for training
dicts_train_small = df_train[small].to_dict(orient='records')
# A new list of dictionaries for validation
dicts_val_small = df_val[small].to_dict(orient='records')


# Initialize a NEW DictVectorizer specifically for the 'small' features.
dv_small = DictVectorizer(sparse=False)
# FIT (learn the three features) and TRANSFORM the training data.
dv_small.fit(dicts_train_small)


dv_small.get_feature_names_out()


# We FIT (tell the program/python to learn the column names from the three features)
# and TRANSFORM the training dictionaries into a numerical matrix.
X_train_small = dv_small.transform(dicts_train_small)


model_small = LogisticRegression(solver='lbfgs')
model_small.fit(X_train_small, y_train)





# Default bias
w0 = model_small.intercept_[0]
w0


w = model_small.coef_[0]
w.round(3)


dict(zip(dv_small.get_feature_names_out(), w.round(3)))
{'contract=month-to-month': 0.97,
 'contract=one_year': -0.025,
 'contract=two_year': -0.949,
 'monthlycharges': 0.027,
 'tenure': -0.036}


# Z = Intercept + (w_contract * 1) + (w_monthlycharges * 30) + (w_tenure * 24)
-2.47 + (-0.949) + 30 * 0.027 + 24 * (-0.036)


sigmoid(_)








dicts_full_train = df_full_train[categorical + numeric].to_dict(orient='records')


dv = DictVectorizer(sparse=False)
X_full_train = dv.fit_transform(dicts_full_train)


y_full_train = df_full_train.churn.values


model = LogisticRegression(solver='lbfgs')
model.fit(X_full_train, y_full_train)


dicts_test = df_test[categorical + numeric].to_dict(orient='records')


X_test = dv.transform(dicts_test)


y_pred = model.predict_proba(X_test)[:, 1]


churn_decision = (y_pred >= 0.5)


(churn_decision == y_test).mean()


y_test


customer = dicts_test[-1]
customer


X_small = dv.transform([customer])
model.predict_proba(X_small)[0, 1]


y_test[-1]






